{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80574510-86fb-4ac9-8e0e-df43609c5e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "from botocore.session import get_session\n",
    "from botocore.credentials import RefreshableCredentials\n",
    "import faiss\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import os\n",
    "import json\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25248853-d0c6-452a-a26f-87788c2bcb71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988e9b4a-3974-4bc3-9d83-20f5248421ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARN of Role A to assume  \n",
    "role_to_assume = 'arn:aws:iam::605134468121:role/BedrockCrossAccount'\n",
    "\n",
    "def get_credentials():\n",
    "    sts_client = boto3.client('sts')\n",
    "    assumed_role = sts_client.assume_role(\n",
    "        RoleArn=role_to_assume,\n",
    "        RoleSessionName='cross-account-session',\n",
    "        # Don't set DurationSeconds when role chaining\n",
    "    )\n",
    "    return {\n",
    "        'access_key': assumed_role['Credentials']['AccessKeyId'],\n",
    "        'secret_key': assumed_role['Credentials']['SecretAccessKey'],\n",
    "        'token': assumed_role['Credentials']['SessionToken'],\n",
    "        'expiry_time': assumed_role['Credentials']['Expiration'].isoformat()\n",
    "    }\n",
    "\n",
    "session = get_session()\n",
    "refresh_creds = RefreshableCredentials.create_from_metadata(\n",
    "    metadata=get_credentials(),\n",
    "    refresh_using=get_credentials,\n",
    "    method='sts-assume-role'\n",
    ")\n",
    "\n",
    "# Create a new session with refreshable credentials\n",
    "session._credentials = refresh_creds\n",
    "boto3_session = boto3.Session(botocore_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72235c91-ab0f-44b5-b1fb-7c1df1d45f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region: str = \"us-west-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb15d1b-6079-4919-aa5a-2dafe713da84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_aws\n",
      "  Downloading langchain_aws-0.2.13-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: boto3>=1.35.74 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_aws) (1.36.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_aws) (0.3.36)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_aws) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain_aws) (2.10.6)\n",
      "Requirement already satisfied: botocore<1.37.0,>=1.36.18 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.35.74->langchain_aws) (1.36.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.35.74->langchain_aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.35.74->langchain_aws) (0.11.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_aws) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3,>=2->langchain_aws) (2.27.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.37.0,>=1.36.18->boto3>=1.35.74->langchain_aws) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.37.0,>=1.36.18->boto3>=1.35.74->langchain_aws) (1.26.19)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.37.0,>=1.36.18->boto3>=1.35.74->langchain_aws) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (3.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain_aws) (1.3.1)\n",
      "Downloading langchain_aws-0.2.13-py3-none-any.whl (99 kB)\n",
      "Installing collected packages: langchain_aws\n",
      "Successfully installed langchain_aws-0.2.13\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langchain_aws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ae0320-f70b-447f-bc5a-7f56b53c41fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "import boto3\n",
    "\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = boto3_session.client(\"bedrock-runtime\",\n",
    "                              region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "516b6212-9849-4cad-8ac5-bee68a8a0e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatBedrockConverse(\n",
    "    client=bedrock_client,\n",
    "    model_id=\"us.amazon.nova-micro-v1:0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c626afa-0d76-4c58-84f9-d8ecb8364c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/_distutils_hack/__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "2025-02-19 04:40:35.700659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-19 04:40:43.696826: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-19 04:40:43.750604: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-19 04:40:54.832707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-19 04:41:04.137680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Transformers is only compatible with Keras 2, but you have explicitly set `TF_USE_LEGACY_KERAS` to `0`. This may result in unexpected behaviour or errors if Keras 3 objects are passed to Transformers models.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabfab4833d64bffb0035667cd6ccbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06560f735ba94f2e81348e51336ae3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d17c91716c844e4bfc6ac15161384ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/90.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0305db1cd4c420e955e3be248807b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18a6890829841dd8febc6504a3210c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755a02a12504455789725a11b9b89912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bf70fc39b44efc9b788bfc0d551253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8c775d86894eda8ab0a0637834c52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa9cf04e577472385aa70433a690bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ed780245b24f36a24aaaf43a20b311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65afa0074c0436a83fc853af4c0606f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faiss_index_path = 'faiss_index/faiss_index.index'\n",
    "faiss_index = faiss.read_index(faiss_index_path)\n",
    "embeddings_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "with open(os.path.join('faiss_index', 'metadata.json'), 'r') as f:\n",
    "    metadata = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05076def-8ab6-4a09-bd68-83267f023858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docstore = {}\n",
    "for i, meta in enumerate(metadata):\n",
    "    doc = Document(page_content = meta.get(\"cotent\", \"A\"), metadata = meta)\n",
    "    docstore[i] = doc\n",
    "    \n",
    "doc = InMemoryDocstore(docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98d4f46-f51e-47d7-9f61-c7e036425f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "#docstore = {metadata[\"id\"]: metadata[\"subreddit\"] for meta in metadata}\n",
    "index_to_docstore_id = {i: doc_id for i, doc_id in enumerate(docstore.keys())}\n",
    "#{i: meta[\"id\"] for i, meta in enumerate(metadata)}\n",
    "\n",
    "vectorstore = FAISS(\n",
    "    embeddings_model.embed_query,\n",
    "    index=faiss_index,\n",
    "    docstore=doc,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2912078a-8017-4821-825f-d78cfddefe5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2513fba-c2be-4594-af78-eb1de862da29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d6689-4c16-47bb-9423-bb24c4368b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b69957-3c47-4736-9ef0-da4fe78a8ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results1 = rag_chain.invoke(\n",
    "    {\"input\": \"Compare and contrast coffee shops in New York and DC.\"}\n",
    ")\n",
    "output1 = {\"question\" : results1[\"input\"], \n",
    "           \"context\": [r.metadata for r in results1[\"context\"]], \n",
    "          \"answer\": results1[\"answer\"]}\n",
    "\n",
    "#print(results1[\"context\"][0].metadata)\n",
    "with open(\"problem3_task1.txt\", \"w\") as f:\n",
    "    json.dump(output1, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b8977ca-e164-4c7c-81d3-bc6f2f3766d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever2 = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"filter\": lambda doc: doc.get(\"num_comments\") is not None and doc.get(\"num_comments\") > 10\n",
    "})\n",
    "\n",
    "rag_chain2 = create_retrieval_chain(retriever2, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "309e51a1-746f-43e3-aed8-8669ae83fa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results2 = rag_chain2.invoke(\n",
    "    {\"input\": \"Common themes discussed in the NYC and DC subreddits.\"}\n",
    ")\n",
    "output2 = {\"question\" : results2[\"input\"], \n",
    "           \"context\": [r.metadata for r in results2[\"context\"]], \n",
    "          \"answer\": results2[\"answer\"]}\n",
    "\n",
    "#print(results1[\"context\"][0].metadata)\n",
    "with open(\"problem3_task2.txt\", \"w\") as f:\n",
    "    json.dump(output2, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163a370-8ade-454f-a3b0-cd6dfe64a4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a0cb2f-6471-4d60-817c-65def87f0bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_ids = list(vectorstore.index_to_docstore_id.values())\n",
    "\n",
    "# Retrieve each document using the docstore's search method\n",
    "docs = [vectorstore.docstore.search(doc_id) for doc_id in doc_ids]\n",
    "\n",
    "retriever_vectordb = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4})\n",
    "keyword_retriever = BM25Retriever.from_documents(docs)\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever_vectordb, keyword_retriever], weights=[0.5, 0.5])\n",
    "\n",
    "rag_chain_e = create_retrieval_chain(ensemble_retriever, question_answer_chain)\n",
    "\n",
    "results3 = rag_chain_e.invoke(\n",
    "    {\"input\": \"Write a newspaper article on how do creative people sustain themselves in NYC and is same as what creative people in DC do. Quote relevant posts from reddit. Sign the article by a made up name that is based on the data in the subreddits\"}\n",
    ")\n",
    "\n",
    "output3 = {\"question\" : results3[\"input\"], \n",
    "           \"context\": [r.metadata for r in results3[\"context\"]], \n",
    "          \"answer\": results3[\"answer\"]}\n",
    "\n",
    "#print(results1[\"context\"][0].metadata)\n",
    "with open(\"problem3_task3.txt\", \"w\") as f:\n",
    "    json.dump(output3, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88fc24-53a9-4971-be72-1bc282437874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
